{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22b39234",
   "metadata": {},
   "source": [
    "# Tests of cosmic homogeneity\n",
    "This notebook is part of the *DoCrimes* project <https://github.com/davidwhogg/DoCrimes>.\n",
    "\n",
    "## Authors\n",
    "- **David W. Hogg** (NYU) (MPIA) (Flatiron)\n",
    "\n",
    "## License\n",
    "- This code is licensed for re-use under the open-source *MIT License*. See the file `LICENSE` for more information.\n",
    "\n",
    "## To-do items and bugs:\n",
    "- Actually use the jackknifes.\n",
    "- Fix things such that `jack_and_repack()` doesn't need to do so much repacking.\n",
    "- Make a quantitative estimate of the fractal dimension.\n",
    "- Switch to a color scheme that is good in black-and-white.\n",
    "- Figure out a way to estimate a \"comoving volume\" for the sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789882e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from scipy.spatial import KDTree\n",
    "from astropy.io import fits\n",
    "from astropy.io import ascii\n",
    "from astropy.table import QTable\n",
    "from astropy import units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.cosmology import Planck18\n",
    "import pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9353a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set some standards.\n",
    "clobber = False\n",
    "rng = np.random.default_rng(17)\n",
    "RECTFIG = [6., 3.5]\n",
    "SQUAREFIG = [6., 6.]\n",
    "dpi = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e297433e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Bright Star Catalog (don't forget to cite this!).\n",
    "r = ascii.get_reader(ascii.Cds, readme=\"../data/bsc/ReadMe2\") # horrifying file path\n",
    "bsc_table = r.read(\"../data/bsc/catalog\")\n",
    "bright = bsc_table['Vmag'] < 4.\n",
    "bsc_table = bsc_table[bright]\n",
    "print(len(bsc_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16091bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the quasar catalog.\n",
    "datafd = fits.open(\"../data/gaia_G20.0.fits\") # terrible file path\n",
    "data_table = QTable(datafd[1].data)\n",
    "print(len(data_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85838d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_table.colnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d272239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the random catalog.\n",
    "randfd = fits.open(\"../data/random_stardustm1064_G20.0_10x.fits\") # upsetting file path\n",
    "rand_table = QTable(randfd[1].data)\n",
    "print(len(rand_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9df2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS A WRONG HACK. THERE IS A TRUE FACTOR, WHICH WE SHOULD USE.\n",
    "factor = len(data_table) / len(rand_table)\n",
    "print(factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba30e046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut everything by the dust map.\n",
    "ebvlim = 0.05\n",
    "Id = data_table['ebv'] < ebvlim\n",
    "data_table = data_table[Id]\n",
    "Ir = rand_table['ebv'] < ebvlim\n",
    "rand_table = rand_table[Ir]\n",
    "print(len(data_table), len(rand_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c80c2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give l,b values to BSC.\n",
    "bsc_table['ra']  = np.zeros_like(bsc_table['RAh']) + np.NaN\n",
    "bsc_table['dec'] = np.zeros_like(bsc_table['RAh']) + np.NaN\n",
    "bsc_table['l']   = np.zeros_like(bsc_table['RAh']) + np.NaN\n",
    "bsc_table['b']   = np.zeros_like(bsc_table['RAh']) + np.NaN\n",
    "for i in range(len(bsc_table)):\n",
    "    rastr = \"{:02d}h{:02d}m{:04.1f}s\".format(bsc_table['RAh'][i],\n",
    "                                         bsc_table['RAm'][i],\n",
    "                                         bsc_table['RAs'][i])\n",
    "    decstr = \"{}{:02d}d{:02d}m{:02d}s\".format(bsc_table['DE-'][i],\n",
    "                                          bsc_table['DEd'][i],\n",
    "                                          bsc_table['DEm'][i],\n",
    "                                          bsc_table['DEs'][i])\n",
    "    try:\n",
    "        foo = SkyCoord(rastr, decstr, frame=\"icrs\")\n",
    "        bsc_table['ra'][i]  = foo.ra.to(u.deg).value\n",
    "        bsc_table['dec'][i] = foo.dec.to(u.deg).value\n",
    "        bsc_table['l'][i] = foo.galactic.l.to(u.deg).value\n",
    "        bsc_table['b'][i] = foo.galactic.b.to(u.deg).value\n",
    "    except:\n",
    "        pass\n",
    "print(len(bsc_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebd530a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overwrite l, b in the data catalog.\n",
    "datac = SkyCoord(ra=data_table['ra']*u.degree, dec=data_table['dec']*u.degree, frame='icrs')\n",
    "data_table['l'] = datac.galactic.l.to(u.deg).value\n",
    "data_table['b'] = datac.galactic.b.to(u.deg).value\n",
    "print(len(data_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb52736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add l, b to the random catalog.\n",
    "randc = SkyCoord(ra=rand_table['ra']*u.degree, dec=rand_table['dec']*u.degree, frame='icrs')\n",
    "rand_table['l'] = randc.galactic.l.to(u.deg).value\n",
    "rand_table['b'] = randc.galactic.b.to(u.deg).value\n",
    "print(len(rand_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010df0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make two hemsisphere samples, and plotting comparison samples.\n",
    "dhi, dlo = data_table['b'] > 0., data_table['b'] < 0.\n",
    "rhi, rlo = rand_table['b'] > 0., rand_table['b'] < 0.\n",
    "plot_rhi, plot_rlo = rhi.copy(), rlo.copy()\n",
    "plot_rhi[len(data_table):] = False\n",
    "plot_rlo[len(data_table):] = False\n",
    "print(np.sum(dhi), np.sum(dlo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad5b301",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bsc_size(bsc):\n",
    "    return np.clip(4.5 - bsc['Vmag'], 0., None) ** 2.\n",
    "\n",
    "def plot_bsc(ax, bsc):\n",
    "    ax.scatter(bsc['ra'], bsc['dec'], color='k', marker='o', alpha=0.5,\n",
    "               edgecolors=\"none\",\n",
    "               s = _bsc_size(bsc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a631422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the objects on the sky in (ra, dec).\n",
    "scatterkwargs = {'marker':'o',\n",
    "                 's': 0.3,\n",
    "                 'alpha':0.5, \n",
    "                 'edgecolors': 'none',\n",
    "                }\n",
    "\n",
    "fig = plt.figure(figsize=RECTFIG)\n",
    "fig.set_tight_layout(True)\n",
    "for I in [dhi, dlo]:\n",
    "    plt.scatter(data_table['ra'][I], data_table['dec'][I],\n",
    "                **scatterkwargs)\n",
    "plot_bsc(plt.gca(), bsc_table)\n",
    "plt.xlim(360, 0)\n",
    "plt.ylim(-90, 90)\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.xlabel(\"RA (deg)\")\n",
    "plt.ylabel(\"Dec (deg)\")\n",
    "plt.title(\"sky distribution\")\n",
    "plt.savefig(\"radec.png\", dpi=dpi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6410f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't do this.\n",
    "if False:\n",
    "    for I in [dhi, dlo]:\n",
    "        plt.scatter(data_table['l'][I] * np.pi / 180.,\n",
    "                    np.sin(data_table['b'][I] * np.pi / 180.),\n",
    "                    **scatterkwargs)\n",
    "    plt.ylim(-1, 1)\n",
    "    plt.xlim(0, np.pi)\n",
    "    plt.xlabel(\"Galactic longitude (rad)\")\n",
    "    plt.ylabel(\"sine of Galactic latitude\")\n",
    "    plt.title(\"data\")\n",
    "    plt.savefig(\"lb.png\", dpi=dpi)\n",
    "\n",
    "    plt.figure()\n",
    "    for I in [plot_rhi, plot_rlo]:\n",
    "        plt.scatter(rand_table['l'][I] * np.pi / 180.,\n",
    "                    np.sin(rand_table['b'][I] * np.pi / 180.),\n",
    "                    **scatterkwargs)\n",
    "    plt.ylim(-1, 1)\n",
    "    plt.xlim(0, np.pi)\n",
    "    plt.xlabel(\"Galactic longitude (rad)\")\n",
    "    plt.ylabel(\"sine of Galactic latitude\")\n",
    "    plt.title(\"a sampling of the random catalog\")\n",
    "    plt.savefig(\"lb_random.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639ce7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hogg_sky_plot(data, title, Is, bsc=None, **kwargs):\n",
    "    \"\"\"\n",
    "    ## inputs:\n",
    "    - `data`: table that must contain `l` longitudes in deg and `b` latitudes in deg.\n",
    "    - `title`: plot title\n",
    "    - `Is` : a list of boolean indices that index the data.\n",
    "    - `**kwargs`: passed to scatter.\n",
    "    \n",
    "    ## bugs:\n",
    "    - Should probably use astropy units.\n",
    "    \"\"\"\n",
    "    xoff = np.sqrt(2.)\n",
    "    def _project(ls, bs, xoff):\n",
    "        thetas = ls\n",
    "        rs = np.sqrt(2. - 2. * np.sin(np.abs(bs)))\n",
    "        return (rs * np.cos(thetas) - xoff) * np.sign(bs) * -1., rs * np.sin(thetas)\n",
    "    def _plot_grid(ax, xoff, fontdict=None):\n",
    "        # make background\n",
    "        ls1 = np.arange(0., 1.0001, 0.001) * np.pi\n",
    "        ls2 = 2. * np.pi - ls1\n",
    "        bs = np.zeros_like(ls1) + 0.0001 * np.pi\n",
    "        for sign in (1., -1.):\n",
    "            xs, ys1 = _project(ls1, sign * bs, xoff)\n",
    "            _,  ys2 = _project(ls2, sign * bs, xoff)\n",
    "            ax.fill_between(xs, ys1, ys2, color=\"w\", zorder=-np.Inf)\n",
    "        # make l grid\n",
    "        bs = np.array([0.5, 0.1, 0.0001]) * np.pi\n",
    "        for l in np.arange(0, 359, 30).astype(int):\n",
    "            ls = np.zeros_like(bs) + l * np.pi / 180.\n",
    "            for sign in (1., -1.):\n",
    "                xs, ys = _project(ls, sign * bs, xoff)\n",
    "                ax.plot(xs, ys, \"k-\", lw=0.5, alpha=0.5)\n",
    "                if fontdict is not None:\n",
    "                    lstr = \"{}\".format(l)\n",
    "                    ax.text(xs[-2], ys[-2], lstr, fontdict=fontdict)\n",
    "        # make b grid\n",
    "        ls = np.arange(0., 360.01, 1.) * np.pi / 180.\n",
    "        for b in (10, 30, 50, 70):\n",
    "            bs = np.zeros_like(ls) + b * np.pi / 180.\n",
    "            for sign in (1., -1.):\n",
    "                xs, ys = _project(ls, sign * bs, xoff)\n",
    "                ax.plot(xs, ys, \"k-\", lw=0.5, alpha=0.5)\n",
    "                if fontdict is not None:\n",
    "                    bstr = \"{}\".format(b)\n",
    "                    ax.text(xs[285], ys[285], bstr, fontdict=fontdict)\n",
    "    def _plot_bsc(ax, xoff, bsc):\n",
    "        xs, ys = _project(bsc['l'] * np.pi / 180.,\n",
    "                          bsc['b'] * np.pi / 180., xoff)\n",
    "        ax.scatter(xs, ys, color='k', marker='o', alpha=0.5,\n",
    "                   edgecolors=\"none\",\n",
    "                   s = _bsc_size(bsc))\n",
    "    xs, ys = _project(data['l'] * np.pi / 180.,\n",
    "                      data['b'] * np.pi / 180., xoff)\n",
    "    fig = plt.figure(figsize=RECTFIG)\n",
    "    ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "    ax.set_axis_off()\n",
    "    fig.add_axes(ax)\n",
    "    for I in Is:\n",
    "        ax.scatter(xs[I], ys[I], **kwargs)\n",
    "    labeldict = {'fontsize': 8,\n",
    "                 'fontweight': 1,\n",
    "                 'verticalalignment': 'center',\n",
    "                 'horizontalalignment': 'center',\n",
    "                 'alpha': 0.5}\n",
    "    _plot_grid(ax, xoff, labeldict)\n",
    "    if bsc is not None:\n",
    "        _plot_bsc(ax, xoff, bsc)\n",
    "    ax.set_xlim(-2 * xoff, 2 * xoff)\n",
    "    ax.set_ylim(-xoff, xoff)\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "    titledict = {'fontsize': plt.rcParams['axes.titlesize'],\n",
    "                 'fontweight': plt.rcParams['axes.titleweight'],\n",
    "                 'verticalalignment': 'top',\n",
    "                 'horizontalalignment': 'center'}\n",
    "    ax.text(0., 1.35, title, fontdict=titledict)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1034e5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the objects on the sky in (l, b).\n",
    "fig = hogg_sky_plot(data_table, \"data\",\n",
    "                    [dhi, dlo], bsc=bsc_table, **scatterkwargs)\n",
    "fig.savefig(\"lb_better.png\", dpi=dpi, bbox_inches=\"tight\")\n",
    "fig = hogg_sky_plot(rand_table, \"a sampling of the random catalog\",\n",
    "                    [plot_rhi, plot_rlo], bsc=bsc_table, **scatterkwargs)\n",
    "fig.savefig(\"lb_random_better.png\", dpi=dpi, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9d80ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the redshift histograms.\n",
    "bins = np.arange(-0.1, 4.601, 0.1)\n",
    "bincntrs = 0.5 * (bins[1:] + bins[:-1])\n",
    "binwids = (bins[1:] - bins[:-1])\n",
    "nzhi, _ = np.histogram(data_table['redshift_spz'][dhi], bins)\n",
    "nzhi = nzhi.astype(float) / (np.sum(rhi) * factor) / binwids\n",
    "nzlo, _ = np.histogram(data_table['redshift_spz'][dlo], bins)\n",
    "nzlo = nzlo.astype(float) / (np.sum(rlo) * factor) / binwids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99f512f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot redshift histograms.\n",
    "stepkwargs = {'alpha': 0.8,\n",
    "              'where': 'mid',\n",
    "             }\n",
    "\n",
    "fig = plt.figure(figsize=SQUAREFIG)\n",
    "fig.set_tight_layout(True)\n",
    "plt.axhline(0., color=\"k\", lw = 0.5, alpha=0.5)\n",
    "plt.step(bincntrs, nzhi, label=\"NGC\", **stepkwargs)\n",
    "plt.step(bincntrs, nzlo, label=\"SGC\", **stepkwargs)\n",
    "plt.legend()\n",
    "plt.xlim(0., 4.5)\n",
    "plt.xlabel(\"spz redshift\")\n",
    "plt.ylabel(\"fraction per unit redshift\")\n",
    "plt.title(\"redshift distribution\")\n",
    "plt.savefig(\"zhist.png\", dpi=dpi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3a8b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give the random points redshifts.\n",
    "rand_table['redshift_spz'] = rng.choice(data_table['redshift_spz'],\n",
    "                                        size=len(rand_table), replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5b61ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get comoving LOS distances.\n",
    "# This could be sped up if we noted that many redshifts are repeated!\n",
    "data_table['comoving_distance'] = Planck18.comoving_distance(data_table['redshift_spz']).value\n",
    "rand_table['comoving_distance'] = Planck18.comoving_distance(rand_table['redshift_spz']).value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad80eadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cartesian positions in comoving space.\n",
    "def add_xyz(table):\n",
    "    r = table['comoving_distance']\n",
    "    cb = np.cos(table['b'] * np.pi / 180.)\n",
    "    x = r * cb * np.cos(table['l'] * np.pi / 180.)\n",
    "    y = r * cb * np.sin(table['l'] * np.pi / 180.)\n",
    "    z = r * np.sin(table['b'] * np.pi / 180.)\n",
    "    table['xyz'] = np.array([x, y, z]).T\n",
    "    return\n",
    "\n",
    "add_xyz(data_table)\n",
    "add_xyz(rand_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2871a21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make cartesian plots.\n",
    "fig = plt.figure(figsize=SQUAREFIG)\n",
    "fig.set_tight_layout(True)\n",
    "for I in [dhi, dlo]:\n",
    "    plt.scatter(data_table['xyz'][I,0], data_table['xyz'][I,2],\n",
    "                **scatterkwargs)\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.xlim(-5999, 5999)\n",
    "plt.ylim(-7000, 7000)\n",
    "plt.xlabel(\"comoving x (Mpc)\")\n",
    "plt.ylabel(\"comoving z (Mpc)\")\n",
    "plt.savefig(\"cartesianxz.png\", dpi=dpi)\n",
    "\n",
    "fig = plt.figure(figsize=SQUAREFIG)\n",
    "fig.set_tight_layout(True)\n",
    "for I in [dhi, dlo]:\n",
    "    plt.scatter(data_table['xyz'][I,1], data_table['xyz'][I,2],\n",
    "                **scatterkwargs)\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.xlim(-5999, 5999)\n",
    "plt.ylim(-7000, 7000)\n",
    "plt.xlabel(\"comoving y (Mpc)\")\n",
    "plt.ylabel(\"comoving z (Mpc)\")\n",
    "plt.savefig(\"cartesianyz.png\", dpi=dpi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aee5f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_pair_counts(data_table, rand_table, factor):\n",
    "\n",
    "    # Make subsample indices.\n",
    "    dhi = data_table['b'] > 0.\n",
    "    dlo = data_table['b'] < 0.\n",
    "    rhi = rand_table['b'] > 0.\n",
    "    rlo = rand_table['b'] < 0.\n",
    "\n",
    "    # Make trees in preparation for counting pairs.\n",
    "    print(\"making trees...\")\n",
    "    data_tree = KDTree(data_table['xyz'])\n",
    "    dhi_tree = KDTree(data_table['xyz'][dhi])\n",
    "    dlo_tree = KDTree(data_table['xyz'][dlo])\n",
    "    rand_tree = KDTree(rand_table['xyz'])\n",
    "    rhi_tree = KDTree(rand_table['xyz'][rhi])\n",
    "    rlo_tree = KDTree(rand_table['xyz'][rlo])\n",
    "\n",
    "    # Make the DD counts (cumulative) out to various radii.\n",
    "    # Note the controversial `- N` adjustments to the self-counts.\n",
    "    rs = np.exp(np.arange(np.log(5.), np.log(1000.), 0.25))\n",
    "    print(\"making DD_hi...\")\n",
    "    DD_hi = (dhi_tree.count_neighbors(data_tree, rs).astype(float)\n",
    "             - np.sum(dhi)) # controversial\n",
    "    print(\"making DD_lo...\")\n",
    "    DD_lo = (dlo_tree.count_neighbors(data_tree, rs).astype(float)\n",
    "             - np.sum(dlo)) # controversial\n",
    "\n",
    "    # Make the DR and RD counts.\n",
    "    print(\"making DR_hi...\")\n",
    "    DR_hi = factor * dhi_tree.count_neighbors(rand_tree, rs).astype(float)\n",
    "    print(\"making DR_lo...\")\n",
    "    DR_lo = factor * dlo_tree.count_neighbors(rand_tree, rs).astype(float)\n",
    "    print(\"making RD_hi...\")\n",
    "    RD_hi = factor * rhi_tree.count_neighbors(data_tree, rs).astype(float)\n",
    "    print(\"making RD_lo...\")\n",
    "    RD_lo = factor * rlo_tree.count_neighbors(data_tree, rs).astype(float)\n",
    "\n",
    "    # Make the RR counts.\n",
    "    print(\"making RR_hi...\")\n",
    "    RR_hi = factor ** 2 * (rhi_tree.count_neighbors(rand_tree, rs).astype(float)\n",
    "                           - np.sum(rhi)) # controversial\n",
    "    print(\"making RR_lo...\")\n",
    "    RR_lo = factor ** 2 * (rlo_tree.count_neighbors(rand_tree, rs).astype(float)\n",
    "                           - np.sum(rlo)) # controversial\n",
    "\n",
    "    print(\"done.\")\n",
    "    return rs, np.array([DD_hi, DD_lo]), \\\n",
    "               np.array([DR_hi, DR_lo]), \\\n",
    "               np.array([RD_hi, RD_lo]), \\\n",
    "               np.array([RR_hi, RR_lo])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa127683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count all pairs.\n",
    "fn = \"counts.pkl\"\n",
    "rs = None\n",
    "if os.path.exists(fn):\n",
    "    with open(fn, \"rb\") as fd:\n",
    "        rs, DD, DR, RD, RR = pickle.load(fd)\n",
    "if rs is None or clobber:\n",
    "    rs, DD, DR, RD, RR = all_pair_counts(data_table, rand_table, factor)\n",
    "    with open(fn, \"wb\") as fd:\n",
    "        pickle.dump((rs, DD, DR, RD, RR), fd)\n",
    "print(rs.shape, DD.shape, RR.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16420ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jack_and_repack(data_table, rand_table, factor):\n",
    "    DD = []\n",
    "    DR = []\n",
    "    RD = []\n",
    "    RR = []\n",
    "\n",
    "    dell = 30. # deg\n",
    "    for ell1 in np.arange(0., 359., dell):\n",
    "        ell2 = ell1 + dell\n",
    "        dI = np.logical_or(data_table['l'] < ell1, data_table['l'] >= ell2)\n",
    "        rI = np.logical_or(rand_table['l'] < ell1, rand_table['l'] >= ell2)\n",
    "        print(\"working on\", ell1, ell2, np.sum(dI), np.sum(rI))\n",
    "\n",
    "        _, DD1, DR1, RD1, RR1 = all_pair_counts(data_table[dI], rand_table[rI], factor)\n",
    "\n",
    "        DD += [DD1, ]\n",
    "        print(np.array(DD).shape)\n",
    "        DR += [DR1, ]\n",
    "        RD += [RD1, ]\n",
    "        RR += [RR1, ]\n",
    "\n",
    "    return np.array(DD), np.array(DR), np.array(RD), np.array(RR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aecdff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jackknife the shit out of everything.\n",
    "fn = \"jacks.pkl\"\n",
    "DD_jack = None\n",
    "if os.path.exists(fn):\n",
    "    with open(fn, \"rb\") as fd:\n",
    "        DD_jack, DR_jack, RD_jack, RR_jack \\\n",
    "        = pickle.load(fd)\n",
    "if DD_jack is None or clobber:\n",
    "    DD_jack, DR_jack, RD_jack, RR_jack \\\n",
    "        = jack_and_repack(data_table, rand_table, factor)\n",
    "    with open(fn, \"wb\") as fd:\n",
    "        pickle.dump((DD_jack, DR_jack, RD_jack, RR_jack),\n",
    "                    fd)\n",
    "print(rs.shape, DD_jack.shape, DR_jack.shape, RD_jack.shape, RR_jack.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9268ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make DD and put an error bar on it!\n",
    "njack = len(DD_jack)\n",
    "DDall = np.sum(DD, axis=0)\n",
    "DD_jack_mean = np.mean(DD_jack, axis=0)[None, :, :]\n",
    "DDall_var = ((njack - 1.) / njack) * np.sum(np.sum(DD_jack -\n",
    "                                                   DD_jack_mean,\n",
    "                                                   axis=1) ** 2,\n",
    "                                            axis=0)\n",
    "DDall_err = np.sqrt(DDall_var)\n",
    "print(DDall.shape, DDall_err.shape, DDall_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae48c549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the fractal dimension.\n",
    "plotkwargs = {'linestyle': 'none', 'marker': 'o', 'alpha': 0.8, }\n",
    "\n",
    "fig = plt.figure(figsize=SQUAREFIG)\n",
    "fig.set_tight_layout(True)\n",
    "plt.errorbar(rs, DDall, yerr=DDall_err, color=\"k\", **plotkwargs)\n",
    "plt.loglog()\n",
    "plt.xlabel(\"maximum comoving pair separation (Mpc)\")\n",
    "plt.ylabel(\"cumulative number of pairs\")\n",
    "plt.title(\"pair counts\")\n",
    "plt.savefig(\"cumulativeDD.png\", dpi=dpi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422c59bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make DD ratio to an expectation and put an error bar on it!\n",
    "DDoverexp = np.sum(DD, axis=0) / np.sum(DR + RD - RR, axis=0)\n",
    "DDoverexp_jack = np.sum(DD_jack, axis=1) / np.sum(DR_jack +\n",
    "                                                  RD_jack -\n",
    "                                                  RR_jack,\n",
    "                                                  axis=1)\n",
    "DDoverexp_mean = np.mean(DDoverexp_jack, axis=0)[None, :]\n",
    "DDoverexp_var = ((njack - 1.) / njack) * np.sum((DDoverexp_jack -\n",
    "                                                 DDoverexp_mean) ** 2,\n",
    "                                                axis=0)\n",
    "DDoverexp_err = np.sqrt(DDoverexp_var)\n",
    "print(DDoverexp.shape, DDoverexp_jack.shape, DDoverexp_err.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556912e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the difference from the D=3 expectation\n",
    "fig, axes = plt.subplots(2, 1, sharex=True, figsize=SQUAREFIG)\n",
    "fig.set_tight_layout(True)\n",
    "uniform = rs ** 3\n",
    "ax = axes[0]\n",
    "ax.errorbar(rs, DDall, yerr=DDall_err, color=\"k\", **plotkwargs)\n",
    "ax.loglog()\n",
    "ax.set_ylabel(\"cumulative number of pairs\")\n",
    "ax.set_title(\"pair counts\")\n",
    "ax = axes[1]\n",
    "ax.axhline(1, color=\"k\", lw=1, alpha=0.5)\n",
    "ax.errorbar(rs, DDoverexp, yerr=DDoverexp_err, color=\"k\", **plotkwargs)\n",
    "ax.semilogx()\n",
    "ax.set_xlabel(\"maximum comoving pair separation (Mpc)\")\n",
    "ax.set_ylabel(\"number relative to expectation\")\n",
    "plt.savefig(\"cumulativeDD_DR.png\", dpi=dpi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5af3ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now turn the cumulative counts into differential counts.\n",
    "dDD = DD[:, 1:] - DD[:, :-1]\n",
    "dDD_jack = DD_jack[:, :, 1:] - DD_jack[:, :, :-1]\n",
    "d2DR = DR[:, 1:] - DR[:, :-1] \\\n",
    "     + RD[:, 1:] - RD[:, :-1]\n",
    "d2DR_jack = DR_jack[:, :, 1:] - DR_jack[:, :, :-1] \\\n",
    "          + RD_jack[:, :, 1:] - RD_jack[:, :, :-1]\n",
    "dRR = RR[:, 1:] - RR[:, :-1]\n",
    "dRR_jack = RR_jack[:, :, 1:] - RR_jack[:, :, :-1]\n",
    "rcs = np.exp(0.5 * (np.log(rs[1:]) + np.log(rs[:-1])))\n",
    "print(rcs.shape, d2DR.shape, d2DR_jack.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1a1a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate the correlation function.\n",
    "LS = (dDD - d2DR + dRR) / dRR\n",
    "LS_jack = (dDD_jack - d2DR_jack + dRR_jack) / dRR_jack\n",
    "LS_mean = np.mean(LS_jack, axis=0)[None, :, :]\n",
    "LS_var = np.sum((LS_jack - LS_mean) ** 2, axis=0)\n",
    "LS_err = np.sqrt(LS_var)\n",
    "print(LS.shape, LS_jack.shape, LS_mean.shape, LS_err.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774e0758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the correlation function.\n",
    "fig = plt.figure(figsize=SQUAREFIG)\n",
    "fig.set_tight_layout(True)\n",
    "plt.axhline(0., color=\"k\", lw=0.5, alpha=0.5)\n",
    "plt.errorbar(rcs, LS[0, :], yerr=LS_err[0, :], label=\"NGC\", **plotkwargs)\n",
    "plt.errorbar(rcs, LS[1, :], yerr=LS_err[1, :], label=\"SGC\", **plotkwargs)\n",
    "plt.loglog()\n",
    "plt.legend()\n",
    "plt.xlim(5., 1000.)\n",
    "plt.xlabel(\"comoving pair separation (Mpc)\")\n",
    "plt.ylabel(\"L-S correlation-function estimate\")\n",
    "plt.title(\"auto-correlation function\")\n",
    "plt.savefig(\"corrfunc.png\", dpi=dpi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098070b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
